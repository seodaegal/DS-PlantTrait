{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/root/kaggle/input/planttraits2024/train.csv'\n",
    "test_path = '/root/kaggle/input/planttraits2024/test.csv'\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not worrying about '_sd' columns for now\n",
    "sd_columns = [col for col in train.columns if col.endswith('_sd')]\n",
    "train = train.drop(columns=sd_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target columns\n",
    "mean_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = \"/root/kaggle/input/planttraits2024/train_images/\"\n",
    "test_image_path = \"/root/kaggle/input/planttraits2024/test_images/\"\n",
    "train['image_path'] = train_image_path + train['id'].astype(str) + '.jpeg'\n",
    "test['image_path'] = test_image_path+ test['id'].astype(str) + '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in mean_columns:\n",
    "    upper_quantile = train[column].quantile(0.98)\n",
    "    train = train[(train[column] < upper_quantile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X4_mean</th>\n",
       "      <th>X11_mean</th>\n",
       "      <th>X18_mean</th>\n",
       "      <th>X50_mean</th>\n",
       "      <th>X26_mean</th>\n",
       "      <th>X3112_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>0.50187</td>\n",
       "      <td>15.777546</td>\n",
       "      <td>1.873923</td>\n",
       "      <td>1.539447</td>\n",
       "      <td>11.364504</td>\n",
       "      <td>1209.36037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6545 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X4_mean   X11_mean  X18_mean  X50_mean   X26_mean  X3112_mean\n",
       "0     0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "1     0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "2     0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "3     0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "4     0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "...       ...        ...       ...       ...        ...         ...\n",
       "6540  0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "6541  0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "6542  0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "6543  0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "6544  0.50187  15.777546  1.873923  1.539447  11.364504  1209.36037\n",
       "\n",
       "[6545 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_values = train[mean_columns].mean()\n",
    "test[mean_columns] = mean_values\n",
    "test[mean_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.8/dist-packages (0.7.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet_pytorch) (1.14.0a0+44dac51)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (2.6.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch->efficientnet_pytorch) (1.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_model():\n",
    "    # Load EfficientNetB0 as the base model\n",
    "    base_model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "    # Modify the model's final fully connected layer for regression\n",
    "    num_ftrs = base_model._fc.in_features\n",
    "    base_model._fc = nn.Linear(num_ftrs, len(mean_columns))  # Output layer for regression with multiple outputs\n",
    "\n",
    "    return base_model\n",
    "\n",
    "# Create the model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path, label):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(df, target_col=None, batch_size=32):\n",
    "    paths = df['image_path'].values\n",
    "    \n",
    "    if target_col is not None:\n",
    "        labels = df[target_col].values.astype(np.float32)\n",
    "    else:\n",
    "        labels = np.zeros(len(df), dtype=np.float32)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = [(transform(Image.open(path).convert('RGB')), label) for path, label in zip(paths, labels)]\n",
    "    inputs, labels = zip(*dataset)\n",
    "    inputs = torch.stack(inputs)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, labels)\n",
    "    dataset = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2)\n",
    "        SS_tot = torch.sum((y_true - y_true.mean()) ** 2)\n",
    "        epsilon = 1e-6  # Small epsilon to avoid division by zero\n",
    "        r2_score = 1 - SS_res / (SS_tot + epsilon)\n",
    "        return 1 - r2_score.mean()  # 1에서 R^2 값을 빼서 손실을 계산 (값이 낮을수록 좋음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "columns_to_train = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "models = {}\n",
    "\n",
    "for column in columns_to_train:\n",
    "    model = get_model()\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    \n",
    "    train_df, test_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = create_dataset(train_df, column, batch_size=32)\n",
    "    test_dataset = create_dataset(test_df, column, batch_size=32)\n",
    "    \n",
    "    criterion = R2Loss()  # Using Mean Squared Error loss for regression\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to appropriate device\n",
    "    \n",
    "    print(f\"Training model for {column}\")\n",
    "    for epoch in range(30):  # Assuming you want to train for 30 epoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))  # Assuming labels are reshaped to match output\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Print average training loss for each epoch\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {running_loss / len(train_dataset.dataset)}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for inputs, labels in test_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels.view(-1, 1)).item() * inputs.size(0)\n",
    "        \n",
    "        # Print average test loss\n",
    "        print(f\"Test Loss: {test_loss / len(test_dataset.dataset)}\")\n",
    "    \n",
    "    # Save the model\n",
    "    models[column] = model\n",
    "    torch.save(model.state_dict(), f'model_{column}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X4_mean\n",
      "Epoch 1 - Training Loss: 0.021585435825119306\n",
      "Test Loss: 0.016378742850040293\n",
      "model_X4_mean saved\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X11_mean\n",
      "Epoch 1 - Training Loss: 44.8337281892088\n",
      "Test Loss: 41.138216396730805\n",
      "model_X11_mean saved\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dataset = create_dataset(test)\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "#'X3112_mean' had negative R2 - not prediction for\n",
    "predict_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean']\n",
    "\n",
    "for column in predict_columns:\n",
    "    # Making predictions\n",
    "    preds = models[column].predict(test_data_dataset)\n",
    "    # Flatten the predictions and store them\n",
    "    test[column] = preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean']\n",
    "\n",
    "for column in predict_columns:\n",
    "    model = models[column]  # Load the trained model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    preds = []  # List to store predictions\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_data_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds.extend(outputs.cpu().numpy().flatten())  # Flatten the predictions and store them\n",
    "\n",
    "    # Assign the predictions to the respective column\n",
    "    test[column] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
