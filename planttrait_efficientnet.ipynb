{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/root/train.csv')\n",
    "test = pd.read_csv('/root/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not worrying about '_sd' columns for now\n",
    "sd_columns = [col for col in train.columns if col.endswith('_sd')]\n",
    "train = train.drop(columns=sd_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target columns\n",
    "mean_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['image_path'] = '/root/train_images/' + train['id'].astype(str) + '.jpeg'\n",
    "test['image_path'] = '/root/test_images/' + test['id'].astype(str) + '.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in mean_columns:\n",
    "    upper_quantile = train[column].quantile(0.98)\n",
    "    train = train[(train[column] < upper_quantile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X4_mean</th>\n",
       "      <th>X11_mean</th>\n",
       "      <th>X18_mean</th>\n",
       "      <th>X50_mean</th>\n",
       "      <th>X26_mean</th>\n",
       "      <th>X3112_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>0.51282</td>\n",
       "      <td>15.790058</td>\n",
       "      <td>2.553687</td>\n",
       "      <td>1.578751</td>\n",
       "      <td>19.297984</td>\n",
       "      <td>1481.69107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6545 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X4_mean   X11_mean  X18_mean  X50_mean   X26_mean  X3112_mean\n",
       "0     0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "1     0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "2     0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "3     0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "4     0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "...       ...        ...       ...       ...        ...         ...\n",
       "6540  0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "6541  0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "6542  0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "6543  0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "6544  0.51282  15.790058  2.553687  1.578751  19.297984  1481.69107\n",
       "\n",
       "[6545 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_values = train[mean_columns].mean()\n",
    "test[mean_columns] = mean_values\n",
    "test[mean_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_model():\n",
    "    # Load EfficientNetB0 as the base model\n",
    "    base_model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "    # Modify the model's final fully connected layer for regression\n",
    "    num_ftrs = base_model._fc.in_features\n",
    "    base_model._fc = nn.Linear(num_ftrs, len(mean_columns))  # Output layer for regression with multiple outputs\n",
    "\n",
    "    return base_model\n",
    "\n",
    "# Create the model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path, label):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(df, target_col=None, batch_size=32):\n",
    "    paths = df['image_path'].values\n",
    "    \n",
    "    if target_col is not None:\n",
    "        labels = df[target_col].values.astype(np.float32)\n",
    "    else:\n",
    "        labels = np.zeros(len(df), dtype=np.float32)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = [(transform(Image.open(path).convert('RGB')), label) for path, label in zip(paths, labels)]\n",
    "    inputs, labels = zip(*dataset)\n",
    "    inputs = torch.stack(inputs)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, labels)\n",
    "    dataset = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for X4_mean\n",
      "Epoch 1 - Training Loss: 0.021239181947938224\n",
      "Test Loss: 0.020469692918916618\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X11_mean\n",
      "Epoch 1 - Training Loss: 46.747400992312706\n",
      "Test Loss: 43.62801690076394\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X18_mean\n",
      "Epoch 1 - Training Loss: 13.072887767674327\n",
      "Test Loss: 11.20801850649997\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X50_mean\n",
      "Epoch 1 - Training Loss: 0.35687438255804727\n",
      "Test Loss: 0.32672436458942217\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X26_mean\n",
      "Epoch 1 - Training Loss: 2685.941923542746\n",
      "Test Loss: 2390.626837089579\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X3112_mean\n",
      "Epoch 1 - Training Loss: 4885201.972233528\n",
      "Test Loss: 3588214.9550010175\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "columns_to_train = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "models = {}\n",
    "\n",
    "for column in columns_to_train:\n",
    "    model = get_model()\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    \n",
    "    train_df, test_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = create_dataset(train_df, column, batch_size=32)\n",
    "    test_dataset = create_dataset(test_df, column, batch_size=32)\n",
    "    \n",
    "    criterion = nn.MSELoss()  # Using Mean Squared Error loss for regression\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to appropriate device\n",
    "    \n",
    "    print(f\"Training model for {column}\")\n",
    "    for epoch in range(1):  # Assuming you want to train for 1 epoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))  # Assuming labels are reshaped to match output\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Print average training loss for each epoch\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {running_loss / len(train_dataset.dataset)}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for inputs, labels in test_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels.view(-1, 1)).item() * inputs.size(0)\n",
    "        \n",
    "        # Print average test loss\n",
    "        print(f\"Test Loss: {test_loss / len(test_dataset.dataset)}\")\n",
    "    \n",
    "    # Save the model\n",
    "    models[column] = model\n",
    "    torch.save(model.state_dict(), f'model_{column}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X4_mean\n",
      "Epoch 1 - Training Loss: 0.021585435825119306\n",
      "Test Loss: 0.016378742850040293\n",
      "model_X4_mean saved\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Training model for X11_mean\n",
      "Epoch 1 - Training Loss: 44.8337281892088\n",
      "Test Loss: 41.138216396730805\n",
      "model_X11_mean saved\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "columns_to_train = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "models = {}\n",
    "\n",
    "for column in columns_to_train:\n",
    "    model = get_model()\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    \n",
    "    train_df, test_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = create_dataset(train_df, column, batch_size=32)\n",
    "    test_dataset = create_dataset(test_df, column, batch_size=32)\n",
    "    \n",
    "    criterion = nn.MSELoss()  # Using Mean Squared Error loss for regression\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)  # Move model to appropriate device\n",
    "    \n",
    "    print(f\"Training model for {column}\")\n",
    "    for epoch in range(1):  # Assuming you want to train for 1 epoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))  # Assuming labels are reshaped to match output\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Print average training loss for each epoch\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {running_loss / len(train_dataset.dataset)}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for inputs, labels in test_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += criterion(outputs, labels.view(-1, 1)).item() * inputs.size(0)\n",
    "        \n",
    "        # Print average test loss\n",
    "        print(f\"Test Loss: {test_loss / len(test_dataset.dataset)}\")\n",
    "    \n",
    "    # Save the model\n",
    "    models[column] = model\n",
    "    torch.save(model.state_dict(), f'/root/model_{column}.pt')\n",
    "    print(f\"model_{column} saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (39270) does not match length of index (6545)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m         preds\u001b[39m.\u001b[39mextend(outputs\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mflatten())  \u001b[39m# Flatten the predictions and store them\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# Assign the predictions to the respective column\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m test[column] \u001b[39m=\u001b[39m preds\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3978\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3975\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3976\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3977\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3978\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4172\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4163\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4164\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4170\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4171\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4172\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4174\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4175\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4176\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4177\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4178\u001b[0m     ):\n\u001b[1;32m   4179\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4180\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4912\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4909\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4911\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4912\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4913\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (39270) does not match length of index (6545)"
     ]
    }
   ],
   "source": [
    "predict_columns = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean']\n",
    "\n",
    "for column in predict_columns:\n",
    "    model = models[column]  # Load the trained model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    preds = []  # List to store predictions\n",
    "\n",
    "    # Iterate over the test dataset\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_data_dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds.extend(outputs.cpu().numpy().flatten())  # Flatten the predictions and store them\n",
    "\n",
    "    # Assign the predictions to the respective column\n",
    "    test[column] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
